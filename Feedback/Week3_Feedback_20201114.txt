Starting code feedback for Rui, Week3

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 1.61 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week3, .git, Feedback, Week1, miniproject, Week2

Found the following files in parent directory: README.md, .gitignore

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:

**********************************************************************
*~ 
*.tmp
.DS_Store
__pycache__
.log
.Rproj.user
*.Rproj
.RData
.Rhistory
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# My CMEE Coursework Repository

## Coding and Data Abalysis Practices in Ecology and Evolution
## Discription
This is a union of coding and data analysis practices in the realm of life science.

## Languages
Bash, LaTeX, Python, R

## Dependencies
LaTeX, Python, R

## Installation
Please download all of the files in a suitable directory.

## Project Structure and Usage: 
This project is divided into several weeks. Each week focuses on a theme. Details of scripts usage please read README.md in subdirectory.

## Author and contact
Rui Zhang   rui.zhang20@imperial.ac.uk
**********************************************************************

======================================================================
Looking for the weekly directories...

Found 3 weekly directories: Week1, Week2, Week3

The Week3 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK3...

Found the following directories: data, code, sandbox, result

Found the following files: README.md

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:

**********************************************************************
# Week 3 README

## Biological Computing in R Practice
## Discription
This is a union R learning and practicing database, which contains r scripts, input data or files and some of the output files.
There are 4 directories including code, data, result and sandbox. 
- Code contains all of the r scripts.
- Data contains 6 csv files and 2 RData files downloaded from [CMEECourse website](https://github.com/mhasoba/TheMulQuaBio/tree/master/content/data). 
- Result only contains a .gitignore file.
- Sandbox contains test files to practice command usage.

## Languages
R

## Dependencies
maps, ggplot2, tidyvere, dplyr

## Installation
Please download all of the files in a suitable directory.

## Project Structure and Usage: 
**Please remember to run these shell scripts in code directory.**
### Code
- DataWrang.R: Wrangling the Pound Hill Dataset
- DataWrangTidy.R: use tidyverse package command to Wrangle the Pound Hill Dataset
- GPDD_Data.R: using the maps package in R to do mapping with Global Population Dynamics Database(GPDD)
- Girko.R： draw the results of a simulation displaying Girko's circular law
- MyBars.R: use ggplot geom_text to annotate a plot
- PP_Dists.R: draw and save 3 graphics relatively for distribution of log(Predator mass), log(Prey mass) and the size ratio of Prey mass over Predator mass, containing subplots by Type.of.feeding.interaction
- PP_Regress.R: draw and save a pdf file showing linear regression of 18 subsets (all available Feeding Type * Predator life stage combination) of the data and calculate regression results exported to a formatted table in csv
- R_conditionals.R: some examples of functions with conditionals
- Ricker.R: a script shows Ricker model which is a classic discrete population model
- SQLinR.R: R can also also be used to access, update and manage databases, use SQLite to build, manipulate, and access databases
- TAutoCorr.R: autocorrelation in weather, answering whether temperatures of one year are significantly correlated with the next year, across years in a given location
- TAutoCorr.tex: a latex file illustrating TAutoCorr.R results
- TreeHeight.R: This script reads a csv file containing trees' species, distance and angle, calculates all of the trees' height, then append heights to the origin csv file as a new csv file stored in ../result
- Vectorize1.R: an example illustrating that vectorization can optimize code computational efficiency and make code more concise, easy to read, less prone
- Vectorize2.R: Runs the stochastic Ricker equation with gaussian fluctuations in non-vectorization way and vectorization way
- apply1.R: use apply to vectorize code, applying the same function to rows/columns of a matrix
- apply2.R: use apply to define your own functions
- basic_io.R: A simple script to illustrate R input-output.
- boilerplate.R: A boilerplate R script
- break.R: a control flow tool, break, is useful to break out of loops when some condition is met
- browse.R: use browser() to debug script, inserting a breakpoint in code and then stepping throuth code
- control_flow.R: control flow tools in R including if, then, else and for and while loops
- next.R: a control flow tool, next, is used to skip to next iteration of a loop
- plotLin.R: mathematical annotation on a axis and in the plot area
- preallocate.R: an example shows pre-allocate a vector can make results faster
- sample.R: an example of vectorization involving lapply and sapply
- try.R: use try keyword to catch the error and keep going instead of having R throw you out

### Data
- EcolArchives-E089-51-D1.csv: import file of PP_Dists.R and PP_Regress.R
- GPDDFiltered.RData: import file of GPDD_Data.R			
- KeyWestAnnualMeanTemperature.RData: import file of TAutoCorr.R
- PoundHillData.csv: import file of DataWrang.R and DataWrangTidy.R
- PoundHillMetaData.csv: import file of DataWrang.R and DataWrangTidy.R
- Resource.csv: import file of SQLinR.R
- Results.txt: import file of MyBars.R
- trees.csv: import file of TreeHeight.R

### Result
An empty directory as origin version only with a .gitignore.

### Sandbox
There is only a pdf file for TAutoCorr.tex

## Author and contact
Rui Zhang   rui.zhang20@imperial.ac.uk
**********************************************************************

Found following files in results directory: MyData.csv, MyLinReg.pdf, Prey_Subplots.pdf, Pred_Subplots.pdf, PP_Results.csv, MyBars.pdf, PP_Regress_Results.csv, PP_Regress.pdf, SizeRatio_Subplots.pdf, TreeHts.csv, gpdd.pdf...

Ideally, Results directory should be empty other than, perhaps a .gitkeep. 

 0.5 pts deducted per results file 

Current Points = 94.5

Found 27 code files: TreeHeight.R, browse.R, preallocate.R, plotLin.R, PP_Dists.R, TAutoCorr.tex, try.R, Vectorize2.R, TAutoCorr.R, boilerplate.R, apply1.R, PP_Regress.R, MyBars.R, DataWrang.R, control_flow.R, Vectorize1.R, SQLinR.R, sample.R, apply2.R, Ricker.R, break.R, next.R, R_conditionals.R, Girko.R, GPDD_Data.R, basic_io.R, DataWrangTidy.R

======================================================================
Testing script/code files...

======================================================================
Inspecting script file TreeHeight.R...

File contents are:

**********************************************************************
# This script reads a csv file containing trees' species, distance and angle, 
# calculates all of the trees' height,
# append heights to the origin csv file as a new csv file stored in ../result
#
# OUTPUT
# A csv file contains the calculated tree heights along with the original data

TreeData <- read.csv('../data/trees.csv')   # read the csv file and store it as a data.frame

# This function calculates heights of trees given distance of each tree 
# from its base and angle to its top, using the trigonometric formula
# 
# height = distance * tan(radians)
#
# ARGUMENTS
# degrees:  The angle of elevation of tree
# distance: The distance from base of tree (e.g. meters)
# 
# OUTPUT
# The heights of the tree, same units as "distance"

TreeHeight <- function(degrees, distance){
  radians <- degrees * pi / 180
  height <- distance * tan(radians)
  return(height)
}

# calculate height of trees and store them as a vector
Height <- c()
for (i in seq(nrow(TreeData))){
  Height <- c(Height, TreeHeight(TreeData[i,2],TreeData[i,3]))
}

# append trees height to the origin dataframe
TreeData$Height.m <- Height

# export dataframe as a csv file
write.csv(TreeData, file = '../result/TreeHts.csv', row.names = F)

**********************************************************************

Testing TreeHeight.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.25079s

======================================================================
Inspecting script file browse.R...

File contents are:

**********************************************************************
# use browser() to debug script, inserting a breakpoint in code and then stepping throuth code

Exponential <- function(N0 = 1, r = 1, generations = 10){
  # Runs a simulation of exponential growth
  # Returns a vector of length generations
  
  N <- rep(NA, generations) # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations){
    N[t] <- N[t-1] * exp(r)
    browser()
  }
  return(N)
}

plot(Exponential(), type="l", main = "Exponential growth")
**********************************************************************

Testing browse.R...

Output (only first 500 characters): 


**********************************************************************
Called from: Exponential()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()
debug: N[t] <- N[t - 1] * exp(r)
debug: browser()

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.26527s

======================================================================
Inspecting script file preallocate.R...

File contents are:

**********************************************************************
# an example shows pre-allocate a vector can make results faster

# a function using for loop that resizes vector repeatedly makes R re-allocate memory repeatedly
NoPreallocFun <- function(x){
  a <- vector()  # empty vector
  for (i in 1:x){
    a <- c(a, i)
    print(a)
    print(object.size(a))
  }
}

# show system time of operating the non-preallocate function
system.time(NoPreallocFun(10))

# a function pre-allocate vector
PreallocFun <- function(x){
  a <- rep(NA, x) # pre-allocated vector
  for (i in 1:x) {
    a[i] <- i
    print(a)
    print(object.size(a))
  }
}

# show system time of operating the preallocate function
system.time(PreallocFun(10))

**********************************************************************

Testing preallocate.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
56 bytes
[1] 1 2
56 bytes
[1] 1 2 3
64 bytes
[1] 1 2 3 4
64 bytes
[1] 1 2 3 4 5
80 bytes
[1] 1 2 3 4 5 6
80 bytes
[1] 1 2 3 4 5 6 7
80 bytes
[1] 1 2 3 4 5 6 7 8
80 bytes
[1] 1 2 3 4 5 6 7 8 9
96 bytes
 [1]  1  2  3  4  5  6  7  8  9 10
96 bytes
   user  system elapsed 
  0.032   0.000   0.032 
 [1]  1 NA NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2 NA NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3 NA NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4 NA NA NA NA NA NA
96 bytes
 [1]  1  2  3  4  5 NA N
**********************************************************************

Code ran without errors or warnings

Time consumed = 0.37416s

======================================================================
Inspecting script file plotLin.R...

File contents are:

**********************************************************************
# mathematical annotation on a axis and in the plot area

library(ggplot2)

# create some linear regression "data"
x <- seq(0,100, by=0.1)
y <- -4. + 0.25*x + rnorm(length(x),mean=0.,sd=2.5)

# put them in a dataframe
my_data <- data.frame(x=x,y=y)

# perform a linear regression
my_lm <- summary(lm(y~x, data=my_data))

# plot the data
p <- ggplot(my_data, aes(x=x,y=y, colour=abs(my_lm$residuals))) + 
  geom_point() + scale_colour_gradient(low="black",high="red") + 
  theme(legend.position = "none") + 
  scale_x_continuous(expression(alpha^2 * pi/beta * sqrt(Theta)))

# add the regression line
p <- p + geom_abline(intercept = my_lm$coefficients[1][1], 
                     slope = my_lm$coefficients[2][1], colour="red")

# throw some math on the plot
p <- p + geom_text(aes(x=60,y=0,label="sqrt(alpha)*2*pi"), parse = T,size=6,colour="blue")


# save the result figure as a file called MyLinReg.pdf
pdf("../result/MyLinReg.pdf")
p
graphics.off()
**********************************************************************

Testing plotLin.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors or warnings

Time consumed = 1.09749s

======================================================================
Inspecting script file PP_Dists.R...

File contents are:

**********************************************************************
# draw and save 3 graphics relatively for distribution of log(Predator mass), log(Prey mass) and
# the size ratio of Prey mass over Predator mass, containing subplots by Type.of.feeding.interaction

# import the data
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv", stringsAsFactors = FALSE)

# change type of certain column to factor
MyDF$Type.of.feeding.interaction <- as.factor(MyDF$Type.of.feeding.interaction)

# subset the dataframe by type.of.feeding.interaction
insectivorous <- subset(MyDF,Type.of.feeding.interaction=="insectivorous")
piscivorous <- subset(MyDF,Type.of.feeding.interaction=="piscivorous")
planktivorous <- subset(MyDF,Type.of.feeding.interaction=="planktivorous")
predacious <- subset(MyDF,Type.of.feeding.interaction=="predacious")
predacious.piscivorous <- subset(MyDF,Type.of.feeding.interaction=="predacious/piscivorous")

# draw Pred_Subplots.pdf
pdf("../result/Pred_Subplots.pdf")
par(mfcol=c(5,1))
par(mfg = c(1,1))
hist(log(insectivorous$Predator.mass), xlab = "log(Predator Mass (g))", ylab = "Count", main = "insectivorous")
hist(log(piscivorous$Predator.mass), xlab = "log(Predator Mass (g))", ylab = "Count", main = "piscivorous")
hist(log(planktivorous$Predator.mass), xlab = "log(Predator Mass (g))", ylab = "Count", main = "planktivorous")
hist(log(predacious$Predator.mass), xlab = "log(Predator Mass (g))", ylab = "Count", main = "predacious")
hist(log(predacious.piscivorous$Predator.mass), xlab = "log(Predator Mass (g))", ylab = "Count", main = "predacious/piscivorous")
graphics.off()

# draw Prey_Subplots.pdf
pdf("../result/Prey_Subplots.pdf")
par(mfcol=c(5,1))
par(mfg = c(1,1))
hist(log(insectivorous$Prey.mass), xlab = "log(Prey Mass (g))", ylab = "Count", main = "insectivorous")
hist(log(piscivorous$Prey.mass), xlab = "log(Prey Mass (g))", ylab = "Count", main = "piscivorous")
hist(log(planktivorous$Prey.mass), xlab = "log(Prey Mass (g))", ylab = "Count", main = "planktivorous")
hist(log(predacious$Prey.mass), xlab = "log(Prey Mass (g))", ylab = "Count", main = "predacious")
hist(log(predacious.piscivorous$Prey.mass), xlab = "log(Prey Mass (g))", ylab = "Count", main = "predacious/piscivorous")
graphics.off()

# draw SizeRatio_Subplots.pdf
pdf("../result/SizeRatio_Subplots.pdf")
par(mfcol=c(5,1))
par(mfg = c(1,1))
hist(log(insectivorous$Prey.mass/insectivorous$Predator.mass), xlab = "log(Prey mass / Predator Mass)", ylab = "Count", main = "insectivorous")
hist(log(piscivorous$Prey.mass/piscivorous$Predator.mass), xlab = "log(Prey mass / Predator Mass)", ylab = "Count", main = "piscivorous")
hist(log(planktivorous$Prey.mass/planktivorous$Predator.mass), xlab = "log(Prey mass / Predator Mass)", ylab = "Count", main = "planktivorous")
hist(log(predacious$Prey.mass/predacious$Predator.mass), xlab = "log(Prey mass / Predator Mass)", ylab = "Count", main = "predacious")
hist(log(predacious.piscivorous$Prey.mass/predacious.piscivorous$Predator.mass), xlab = "log(Prey mass / Predator Mass)", ylab = "Count", main = "predacious/piscivorous")
graphics.off()


# calculating mean and median of log(predator mass), log(prey mass) and 
# ratio of prey mass over predator mass, then save them into a csv file

# calculate means and transform tapply results to dataframes
log.predmass.mean <- tapply(log(MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, mean)
log.predmass.mean <- as.data.frame(log.predmass.mean)
log.preymass.mean <- tapply(log(MyDF$Prey.mass), MyDF$Type.of.feeding.interaction, mean)
log.preymass.mean <- as.data.frame(log.preymass.mean)
log.sizeratio.mean <- tapply(log(MyDF$Prey.mass/MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, mean)
log.sizeratio.mean <- as.data.frame(log.sizeratio.mean)

# calculate medians and transform tapply results to dataframes
log.predmass.median <- tapply(log(MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, median)
log.predmass.median <- as.data.frame(log.predmass.median)
log.preymass.median <- tapply(log(MyDF$Prey.mass), MyDF$Type.of.feeding.interaction, median)
log.preymass.median <- as.data.frame(log.preymass.median)
log.sizeratio.median <- tapply(log(MyDF$Prey.mass/MyDF$Predator.mass), MyDF$Type.of.feeding.interaction, median)
log.sizeratio.median <- as.data.frame(log.sizeratio.median)

# combine all of means and medians together, add feeding type as the first column
total <- cbind(log.predmass.mean, log.predmass.median, log.preymass.mean, log.preymass.median, 
               log.sizeratio.mean, log.sizeratio.median)
total <- cbind(Type.of.feeding.interaction=row.names(total),total)

# export means and medians to a csv file
write.csv(total, "../result/PP_Results.csv", row.names = F)



**********************************************************************

Testing PP_Dists.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.50308s

======================================================================
Inspecting script file TAutoCorr.tex...

File contents are:

**********************************************************************
\documentclass[12pt]{article}
\usepackage{graphicx, caption}

\title{Autocorrelation in Weather}

\author{Rui Zhang}

\date{}

\begin{document}
  \maketitle
  
  \begin{abstract}
    This paper answers whether temperatures of one year are significantly correlated with the next year, across years in a given location, using TAutoCorr.R to calculate correlation and approximately p-value.
  \end{abstract}
  
  \section{Hypothesis}
    Assume one year's temperatures are significantly correlated with the following year's temperatures.
  
  \section{Materials \& Methods}
    Temperatures data is KeyWestAnnualMeanTemperature.Rdata, which is  the temperature in Key West, Florida for 20th century. There are 100 temperature numbers which allow us to get 99 pairs of successive years temperatures.
    
    First, calculate the correlation between these 99 pairs of years temperatures. 
    
    Second, permute the time series randomly and calculate correlation 10000times.
    
    Third, calculate the fraction of correlation coefficients from the second step greater than correlation coefficient calculated in the first step. The fraction is the approximate p-value for the correlation coefficient.
  
  \section{Interpretation}
  The correlation coefficient is 0.3261697, p-value is 2e-04. p-value is small enough for us to give a conclusion that temperatures of one year are significantly correlated with the next year in a given location. Also as Figure 1 showed, one year's temperatures and the following year's temperatures have kind of significant relationship like linear relationship.

  \begin{figure}
    \centering
    \includegraphics[scale=0.5]{../sandbox/TAutoCorr.pdf}
    \caption{Point plot of paired successive years temperatures}
  \end{figure}
  
\end{document}

**********************************************************************

Testing TAutoCorr.tex...

Output (only first 500 characters): 


**********************************************************************
This is pdfTeX, Version 3.14159265-2.6-1.40.20 (TeX Live 2019/Debian) (preloaded format=pdflatex)
 restricted \write18 enabled.
entering extended mode
(./TAutoCorr.tex
LaTeX2e <2020-02-02> patch level 2
L3 programming layer <2020-02-14>
(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls
Document Class: article 2019/12/20 v1.4l Standard LaTeX document class
(/usr/share/texlive/texmf-dist/tex/latex/base/size12.clo))
(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphicx.sty
(/usr/share/t
**********************************************************************

Code ran without errors or warnings

Time consumed = 0.97334s

======================================================================
Inspecting script file try.R...

File contents are:

**********************************************************************
# use try keyword to catch the error and keep going instead of having R throw you out

# write a function
doit <- function(x){
  temp_x <- sample(x, replace = TRUE)
  if(length(unique(temp_x)) > 30){ # only take mean if sample was sufficient
    print(paste("Mean of this sample was:", as.character(mean(temp_x))))
  }
  else{
    stop("Couldn't calculate mean: too few unique values!")
  }
}

popn <- rnorm(50)
hist(popn)

result <- lapply(1:15, function(i) try(doit(popn), FALSE))
class(result)
result

result <- vector("list", 15) # Preallocate/Initialze
for (i in 1:15){
  result[[i]] <- try(doit(popn), FALSE)
}







**********************************************************************

Testing try.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Mean of this sample was: 0.509861077066768"
[1] "Mean of this sample was: 0.355794367288536"
[1] "Mean of this sample was: 0.233860698538254"
[1] "Mean of this sample was: 0.20954177856738"
[1] "Mean of this sample was: 0.375484386368437"
[1] "Mean of this sample was: 0.481824043275821"
[1] "Mean of this sample was: 0.279824261368259"
[1] "Mean of this sample was: 0.406199900679942"
[1] "Mean of this sample was: 0.287366936767672"
[1] "list"
[[1]]
[1] "Error in doit(popn) : Couldn't calculat
**********************************************************************

Encountered error or warning:
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!
Error in doit(popn) : Couldn't calculate mean: too few unique values!

======================================================================
Inspecting script file Vectorize2.R...

File contents are:

**********************************************************************
# Runs the stochastic Ricker equation with gaussian fluctuations

rm(list=ls())

stochrick<-function(p0=runif(1000,.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100)
{
  #initialize
  N<-matrix(NA,numyears,length(p0))
  N[1,]<-p0
  
  for (pop in 1:length(p0)){#loop through the populations
    
    for (yr in 2:numyears){ #for each pop, loop through the years

      N[yr,pop] <- N[yr-1,pop] * exp(r * (1 - N[yr - 1,pop] / K) + rnorm(1,0,sigma))
    
    }
  
  }
 return(N)

}

print("Vectorized Stochastic Ricker takes:")
print(system.time(res1<-stochrick()))


# Now write another function called stochrickvect that vectorizes the above 
# to the extent possible, with improved performance: 

stochrickvect <- function(p=runif(1000,.5,1.5),r=1.2,K=1,sigma=0.2,numyears=100){
  rick <- function(){
    p <- p * exp(r * (1 - p/K)) + rnorm(1,0,sigma)
    return(p)
  }
  result <- sapply(2:numyears, function(i) rick())
  result <- rbind(p, t(result))
  return(result)
}


print("Vectorized Stochastic Ricker takes:")
print(system.time(res2<-stochrickvect()))


**********************************************************************

Testing Vectorize2.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.343   0.015   0.358 
[1] "Vectorized Stochastic Ricker takes:"
   user  system elapsed 
  0.004   0.000   0.004 

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.62670s

======================================================================
Inspecting script file TAutoCorr.R...

File contents are:

**********************************************************************
# autocorralation in weather, answering whether temperatures of one year are 
# signigicantly correlated with the next year, across years in a given location

# load data from a given RData
load("../data/KeyWestAnnualMeanTemperature.Rdata")

# create 2 temperature vector pair successive years temperature
temp <- ats$Temp
temp1 <- temp[-length(temp)]
temp2 <- temp[-1]

# calculate correlation between n-1 pairs of years, n is the total number of years
cor0 <- cor(temp1,temp2)

# define a function to permute time series randomly and calculate correlation
permute <- function(temp){
  sam <- sample(temp,length(temp),replace = F)
  temp1 <- sam[-length(sam)]
  temp2 <- sam[-1]
  return(cor(temp1, temp2))
}

# repeat permute time series10000 times and write correlation in result
result <- sapply(1:10000, function(i) permute(temp))

# filter correlation over original correlation cor0
over <- which(result > cor0)

# calculate approximate p-value
pvalue <- length(over)/10000

print("correlation coefficient is ")
print(cor0)
print("approximate p-value is ")
print(pvalue)

**********************************************************************

Testing TAutoCorr.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error or warning:
Error in readChar(con, 5L, useBytes = TRUE) : cannot open the connection
Calls: load -> readChar
In addition: Warning message:
In readChar(con, 5L, useBytes = TRUE) :
  cannot open compressed file '../data/KeyWestAnnualMeanTemperature.Rdata', probable reason 'No such file or directory'
Execution halted

======================================================================
Inspecting script file boilerplate.R...

File contents are:

**********************************************************************
# A boilerplate R script

MyFunction <- function(Arg1, Arg2){
  # Statements involving Arg1, Arg2:
  print(paste("Argument", as.character(Arg1), "is a", class(Arg1))) # print Arg1's type
  print(paste("Argument", as.character(Arg2), "is a", class(Arg2))) # print Arg2's type
  
  return(c(Arg1, Arg2)) # this is optional, but very useful
}

MyFunction(1,2) # test the function
MyFunction("Riki","Tiki") # A different test
**********************************************************************

Testing boilerplate.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Argument 1 is a numeric"
[1] "Argument 2 is a numeric"
[1] 1 2
[1] "Argument Riki is a character"
[1] "Argument Tiki is a character"
[1] "Riki" "Tiki"

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.20923s

======================================================================
Inspecting script file apply1.R...

File contents are:

**********************************************************************
# use apply to vectorize code, applying the same function to rows/columns of a matrix

## Build a random matrix
M <- matrix(rnorm(100),10,10)

## Take the mean of each row
RowMeans <- apply(M, 1, mean)
print(RowMeans)

## Now the variance
RowVars <- apply(M, 1, var)
print(RowVars)

## By column
ColMeans <- apply(M, 2, mean)
print(ColMeans)

**********************************************************************

Testing apply1.R...

Output (only first 500 characters): 


**********************************************************************
 [1] -0.22901160  0.27029925 -0.09513891 -0.17672354  0.28711401  0.21177204
 [7]  0.26323891 -0.30039524  0.20267908  0.33630347
 [1] 1.0277740 0.2299950 2.5692298 0.4813290 1.3949562 0.3122708 0.8886954
 [8] 0.8263232 1.5025119 0.7756444
 [1]  0.38551416  0.09708769  0.47517830 -0.29340286  0.22412384 -0.18725739
 [7]  0.23689022  0.44699147 -0.21667458 -0.39831336

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.20513s

======================================================================
Inspecting script file PP_Regress.R...

File contents are:

**********************************************************************
# draw and save a pdf file showing linear regression of 18 subsets (all 
# available Feeding Type * Predator life stage combination) of the data
# and calculate regression results exported to a formatted table in csv

# load the data from a csv file
MyDF <- read.csv("../data/EcolArchives-E089-51-D1.csv", stringsAsFactors = FALSE)

# transform 2 character variables to factor variables
MyDF$Type.of.feeding.interaction <- as.factor(MyDF$Type.of.feeding.interaction)
MyDF$Predator.lifestage <- as.factor(MyDF$Predator.lifestage)

# load ggplot2 to draw graphic
library(ggplot2)

# draw the linear regression and origin data point in a graphic and then export in pdf
pdf("../result/PP_Regress.pdf")
qplot(log(Prey.mass), log(Predator.mass), data = MyDF,facets = Type.of.feeding.interaction ~.,colour = Predator.lifestage, 
      shape= I(3)) + geom_smooth(method = "lm", fullrange = TRUE) + theme(legend.position = "bottom")
graphics.off()

# load dplyr and tidyverse packages for the following regression results calculation
library(dplyr)
library(tidyverse)

# create a dataframe including different feeding type and predator life stage pairs (subset couldn't be empty)
allsubset <- MyDF %>% group_by(Type.of.feeding.interaction, Predator.lifestage) %>% count()
allsubset <- as.data.frame(allsubset[,1:2])

# create the colnames of another dataframe showing numeric variables of regression results
regression <- c("regression intercept", "regression slope", "R^2", "F-statistic value", "p-value")

# create new values including unique feeding types and predator life stage
feeding <- unique(MyDF$Type.of.feeding.interaction)
predlife <- unique(MyDF$Predator.lifestage)

# create subsets, do the linear regression and write regression results in the dataframe
for (i in sort(feeding)){
  subset1 <- subset(MyDF, Type.of.feeding.interaction == i)
  for (j in sort(predlife)){
    subset2 <- subset(subset1, Predator.lifestage == j)
    if (length(subset2$Predator.lifestage) != 0){
      model <- lm(log(Predator.mass)~log(Prey.mass), data=subset2)
      regression <- rbind(regression, c(coef(model),broom::glance(model)[[1]], broom::glance(model)[[4]], broom::glance(model)[[5]]))
    }
  }
}

# make the first row as column names
reg <- as.data.frame(regression[-1,])
colnames(reg) <- regression[1,]

# combine subset dataframe and regression numeric varials dataframe together
result <- cbind(allsubset, reg)
row.names(result) <- NULL

# export regression result into a csv file
write.csv(result, "../result/PP_Regress_Results.csv")


**********************************************************************

Testing PP_Regress.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error or warning:
`geom_smooth()` using formula 'y ~ x'
Warning messages:
1: In qt((1 - level)/2, df) : NaNs produced
2: In max(ids, na.rm = TRUE) :
  no non-missing arguments to max; returning -Inf

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ tibble  3.0.3     ✔ purrr   0.3.4
✔ tidyr   1.1.1     ✔ stringr 1.4.0
✔ readr   1.3.1     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
Inspecting script file MyBars.R...

File contents are:

**********************************************************************
# use ggplot geom_text to annotate a plot

rm(list = ls())
library(ggplot2)

# load a csv file as data
a <- read.table("../data/Results.txt", header = TRUE)

a$ymin <- rep(0, dim(a)[1]) # append a column of zeros

# Print the first linerange
p <- ggplot(a)
p <- p + geom_linerange(data = a, aes(x = x, ymin = ymin, ymax = y1, size = (0.5)), colour = "#E69F00",alpha = 1/2, show.legend = FALSE)

# Print the second linerange
p <- p + geom_linerange(data = a, aes(x = x, ymin = ymin, ymax = y2, size = (0.5)), colour = "#56B4E9", alpha = 1/2, show.legend = FALSE)

# Print the third linerange:
p <- p + geom_linerange(data = a, aes(x = x, ymin = ymin, ymax = y3, size = (0.5)), colour = "#D55E00", alpha = 1/2, show.legend = FALSE)

# Annotate the plot with labels:
p <- p + geom_text(data = a, aes(x = x, y = -500, label = Label))

# now set the axis labels, remove the legend, and prepare for bw printing
p <- p + scale_x_continuous("My x axis",breaks = seq(3, 5, by = 0.05)) + scale_y_continuous("My y axis") + theme_bw() + theme(legend.position = "none") 

# save the result figure as a file called MyBars.pdf
pdf("../result/MyBars.pdf")
p
graphics.off()

**********************************************************************

Testing MyBars.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error or warning:
Warning message:
Removed 91 rows containing missing values (geom_text). 

======================================================================
Inspecting script file DataWrang.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############
head(MyData)
dim(MyData)
str(MyData)
fix(MyData) #you can also do this
fix(MyMetaData)

############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############
require(reshape2) # load the reshape2 package

?melt #check out the melt function

MyWrangledData <- melt(TempData, id=c("Cultivation", "Block", "Plot", "Quadrat"), variable.name = "Species", value.name = "Count")

MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

str(MyWrangledData)
head(MyWrangledData)
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

**********************************************************************

Testing DataWrang.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error or warning:
Loading required package: reshape2

======================================================================
Inspecting script file control_flow.R...

File contents are:

**********************************************************************
# control flow tools in R including if, then, else and for and while loops

# if statements
a <- TRUE
if (a == TRUE){
    print("a is TRUE")
    } else {
    print("a is FALSE")
}

# write an if statement on a single line
z <- runif(1)
if (z <= 0.5) {print("Less than a half")}

# indent code for readability
z <- runif(1)
if (z <= 0.5) {
    print("Less than a half")
    }


# for loops, useful to repeat a task over some range of input values
for (i in seq(10)){
    j <- i * i
    print(paste(i, " squared is", j))
}

# loop over a vector of strings
for (species in c('Heliodoxa rubinoides',
                  'Boissonneaua jardini',
                  'Sula nebouxii')){
  print(paste('The species is ', species))
}

# for loop using a pre-existing vector
v1 <- c("a", "bc", "def")
for (i in v1){
    print(i)
}


# while loops, performing an operation till some condition is met
i <- 0
while (i < 10){
    i <- i + 1
    print(i^2)
}
**********************************************************************

Testing control_flow.R...

Output (only first 500 characters): 


**********************************************************************
[1] "a is TRUE"
[1] "Less than a half"
[1] "1  squared is 1"
[1] "2  squared is 4"
[1] "3  squared is 9"
[1] "4  squared is 16"
[1] "5  squared is 25"
[1] "6  squared is 36"
[1] "7  squared is 49"
[1] "8  squared is 64"
[1] "9  squared is 81"
[1] "10  squared is 100"
[1] "The species is  Heliodoxa rubinoides"
[1] "The species is  Boissonneaua jardini"
[1] "The species is  Sula nebouxii"
[1] "a"
[1] "bc"
[1] "def"
[1] 1
[1] 4
[1] 9
[1] 16
[1] 25
[1] 36
[1] 49
[1] 64
[1] 81
[1] 100

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.24980s

======================================================================
Inspecting script file Vectorize1.R...

File contents are:

**********************************************************************
# an example illustrating that vectorization can optimize code computational efficiency 
# and make code more concise, easy to read, less prone

# create a matrix
M <- matrix(runif(1000000),1000,1000)

# create a function to calculate sum of numbers by loops
SumAllElements <- function(M){
  Dimensions <-dim(M)
  Tot <- 0
  for (i in 1:Dimensions[1]){
    for (j in 1:Dimensions[2]) {
      Tot <- Tot + M[i,j]
    }
  }
  return(Tot)
}

# compare system time taken to operating vectorized function and non-vectorized function
print("Using loops, the time taken is:")
print(system.time(SumAllElements(M)))

print("Using the in-built vectorized function, the time taken is:")
print(system.time(sum(M)))
**********************************************************************

Testing Vectorize1.R...

Output (only first 500 characters): 


**********************************************************************
[1] "Using loops, the time taken is:"
   user  system elapsed 
  0.091   0.003   0.096 
[1] "Using the in-built vectorized function, the time taken is:"
   user  system elapsed 
  0.001   0.000   0.002 

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.38194s

======================================================================
Inspecting script file SQLinR.R...

File contents are:

**********************************************************************
# R can also also be used to access, update and manage databases. 
# In particular SQLite allows you to build, manipulate, and access databases easily.

#install the sqlite package
install.packages('sqldf')

# To load the packages
library(sqldf)

# The command below opens a connection to the database.
#If the database does not yet exist, one is created in the working directory of R.
db <- dbConnect(SQLite(), dbname='Test.sqlite')

# Now let's enter some data to the table
# Using the db connection to our database, the data are entered using SQL queries
# The next command just create the table
dbSendQuery(conn = db,
            "CREATE TABLE Consumer
       (OriginalID TEXT,
        ConKingdom TEXT,
        ConPhylum TEXT,
        ConSpecies TEXT)")

# Once the table is created, we can enter the data.
#INSERT specifies where the data is entered (here the School table).
#VALUES contains the data

 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (1, 'Animalia', 'Arthropoda', 'Chaoborus trivittatus')")
 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (2, 'Animalia', 'Arthropoda', 'Chaoborus americanus')")
 dbSendQuery(conn = db,
         "INSERT INTO Consumer
         VALUES (3, 'Animalia', 'Chordata', 'Stizostedion vitreum')")


# Once we have our table, we can query the results using:

dbGetQuery(db, "SELECT * FROM Consumer")
dbGetQuery(db, "SELECT * FROM Consumer WHERE ConPhylum='Chordata'")


# Tables can be also imported from csv files.
# As example, let's use the Biotraits dataset.
# The easiest way is to read the csv files into R as data frames.
# Then the data frames are imported into the database.

Resource <- read.csv("../data/Resource.csv")  # Read csv files into R

# Import data frames into database
 dbWriteTable(conn = db, name = "Resource", value = Resource, row.names = FALSE)

# Check that the data have been correctly imported into the School table.
 dbListTables(db)                 # The tables in the database
 dbListFields(db,"Resource")       # The columns in a table
 dbReadTable(db, "Resource")    # The data in a table

# Before leaving RSQLite, there is a bit of tidying-up to do.
# The connection to the database is closed, and as precaution
# the three data frames are removed from R’s environment.
 dbDisconnect(db)            # Close connection
 rm(list = c("Resource"))   # Remove data frames



**********************************************************************

Testing SQLinR.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error or warning:
Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)
Warning in install.packages("sqldf") :
  'lib = "/usr/local/lib/R/site-library"' is not writable
Error in install.packages("sqldf") : unable to install packages
Execution halted

======================================================================
Inspecting script file sample.R...

File contents are:

**********************************************************************
# an example of vectorization involving lapply and sapply

####### Functions ########

## A function to take a sample of size n from a population "popn" and return its mean
myexperiment <- function(popn,n){
  pop_sample <- sample(popn, n, replace = FALSE)
                       return(mean(pop_sample))
}

## Calculate means using a for loop without preallocation:
loopy_sample1 <- function(popn,n,num){
  result1 <- vector() # Initialize empty vector of size 1
  for (i in 1:num) {
    result1 <- c(result1, myexperiment(popn,n))
  }
  return(result1)
}

## To run "num" iterations of the experiment using a for loop on a vector with preallocation:
loopy_sample2 <- function(popn,n,num){
  result2 <- vector(,num) # Preallocate expected size
  for(i in 1:num){
    result2[i] <- myexperiment(popn,n)
  }
  return(result2)
}

## To run "num" iterations of the experiment using a for loop on a list with preallocation:
loopy_sample3 <- function(popn,n,num){
  result3 <- vector("list", num) # Preallocate expected size
  for(i in 1:num){
    result3[[i]] <- myexperiment(popn,n)
  }
  return(result3)
}

## To run "num" iterations of the experiment using vectorization with lapply:
lapply_sample <- function(popn,n,num){
  result4 <- lapply(1:num, function(i) myexperiment(popn,n))
  return(result4)
}

## To run "num" iterations of the experiment using vectorization with sapply:
sapply_sample <- function(popn,n,num){
  result5 <- sapply(1:num, function(i) myexperiment(popn,n))
  return(result5)
}

popn <- rnorm(1000) # Generate the population
hist(popn)

n <- 20 # sample size for each experiment
num <- 1000 # Number of times to rerun the experiment

print("The loopy, non-preallocation approach takes:" )
print(system.time(loopy_sample1(popn, n, num)))

print("The loopy, but with preallocation approach takes:" )
print(system.time(loopy_sample2(popn, n, num)))

print("The loopy, non-preallocation approach on a list takes:" )
print(system.time(loopy_sample3(popn, n, num)))

print("The vectorized sapply approach takes:" )
print(system.time(sapply_sample(popn, n, num)))

print("The vectorized lapply approach takes:" )
print(system.time(lapply_sample(popn, n, num)))





**********************************************************************

Testing sample.R...

Output (only first 500 characters): 


**********************************************************************
[1] "The loopy, non-preallocation approach takes:"
   user  system elapsed 
  0.040   0.008   0.047 
[1] "The loopy, but with preallocation approach takes:"
   user  system elapsed 
  0.022   0.000   0.022 
[1] "The loopy, non-preallocation approach on a list takes:"
   user  system elapsed 
  0.019   0.000   0.018 
[1] "The vectorized sapply approach takes:"
   user  system elapsed 
  0.015   0.000   0.015 
[1] "The vectorized lapply approach takes:"
   user  system elapsed 
  0.017   0.000   0.
**********************************************************************

Code ran without errors or warnings

Time consumed = 0.58384s

======================================================================
Inspecting script file apply2.R...

File contents are:

**********************************************************************
# use apply to define your own functions

# define a function
SomeOperation <- function(v){ 
  if (sum(v) > 0){
    return(v * 100)
  }
  return(v)
}

# create a matrix
M <- matrix(rnorm(100),10,10)

# print result of defined function applied to matrix
print(apply(M, 1, SomeOperation))
**********************************************************************

Testing apply2.R...

Output (only first 500 characters): 


**********************************************************************
            [,1]        [,2]        [,3]         [,4]        [,5]       [,6]
 [1,] -0.3621333   78.600273  -49.768902  0.176212840 -1.03816998 -1.8561347
 [2,] -0.1371633 -130.079922   81.442501 -0.003176024  0.36059673  0.2170336
 [3,] -0.9273263   78.523255  171.246410  0.295214609  0.09563649  1.2811609
 [4,] -2.8501380   85.674354  161.958007 -0.671455426  0.87303986  0.1406670
 [5,] -0.6601310   -0.509648   26.858887  0.193413920  0.14665644  1.6806177
 [6,] -0.2466479  164.295745  148.68640
**********************************************************************

Code ran without errors or warnings

Time consumed = 0.29632s

======================================================================
Inspecting script file Ricker.R...

File contents are:

**********************************************************************
# a script shows Ricker model which is a classic discrete population model

Ricker <- function(N0=1, r=1, K=10, generations=50){
  # Runs a simulation of the Ricker model
  # Return a vector of length generations
  
  N <- rep(NA, generations)  # Creates a vector of NA
  
  N[1] <- N0
  for (t in 2:generations){
    N[t] <- N[t-1] * exp(r*(1.0 - (N[t-1]/K)))
  }
  return(N)
}

plot(Ricker(generations = 10), type = "l")
**********************************************************************

Testing Ricker.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.28024s

======================================================================
Inspecting script file break.R...

File contents are:

**********************************************************************
# a control flow tool, break, is useful to break out of loops when some condition is met

i <- 0 #Initialize i
    while(i < Inf) {
      if(i == 10) {
        break
      } # Break out of the while loop!
      else {
        cat("i equals " , i , "\n")
        i <- i + 1 # Update i
      }
    }
**********************************************************************

Testing break.R...

Output (only first 500 characters): 


**********************************************************************
i equals  0 
i equals  1 
i equals  2 
i equals  3 
i equals  4 
i equals  5 
i equals  6 
i equals  7 
i equals  8 
i equals  9 

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.25660s

======================================================================
Inspecting script file next.R...

File contents are:

**********************************************************************
# a control flow tool, next, is used to skip to next iteration of a loop

for (i in 1:10){
  if ((i %% 2) == 0) # check if the number is odd
    next # pass to next iteration of loop
  print(i)
}
**********************************************************************

Testing next.R...

Output (only first 500 characters): 


**********************************************************************
[1] 1
[1] 3
[1] 5
[1] 7
[1] 9

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.21952s

======================================================================
Inspecting script file R_conditionals.R...

File contents are:

**********************************************************************
# some examples of functions with conditionals
# Check if an integer is even
is.even <- function(n = 2){
  if (n %% 2 == 0){
    return(paste(n,'is even!'))
  }
  return(paste(n,'is odd!'))
}

is.even(6)

# Check if a number is a power of 2
is.power2 <- function(n = 2){
  if (log2(n) %% 1 == 0){
    return(paste(n, 'is a power of 2!'))
  }
  return(paste(n,'is not a power of 2'))
}

is.power2(4)


# Check if a number is prime
is.prime <- function(n){
  if (n == 0){
    return(paste(n,'is a zero!'))
  }
  if (n == 1){
    return(paste(n,'is just a unit!'))
  }
  ints <- 2:(n-1)
  if (all(n %% ints != 0)){
    return(paste(n,'is a prime'))
  }
  return(paste(n,'is a composite'))
}

is.prime(3)

**********************************************************************

Testing R_conditionals.R...

Output (only first 500 characters): 


**********************************************************************
[1] "6 is even!"
[1] "4 is a power of 2!"
[1] "3 is a prime"

**********************************************************************

Code ran without errors or warnings

Time consumed = 0.20403s

======================================================================
Inspecting script file Girko.R...

File contents are:

**********************************************************************
# draw the results of a simulation displaying Girko's circular law
install.packages("ggplot2")
library(ggplot2)

# firstly, build a function calculating the ellipse
build_ellipse <- function(hradius, vradius){ # function that returns an ellipse
  npoints = 250
  a <- seq(0, 2 * pi, length = npoints + 1)
  x <- hradius * cos(a)
  y <- vradius * sin(a)  
  return(data.frame(x = x, y = y))
}

N <- 250 # Assign size of the matrix

M <- matrix(rnorm(N * N), N, N) # Build the matrix

eigvals <- eigen(M)$values # Find the eigenvalues

eigDF <- data.frame("Real" = Re(eigvals), "Imaginary" = Im(eigvals)) # Build a dataframe

my_radius <- sqrt(N) # The radius of the circle is sqrt(N)

ellDF <- build_ellipse(my_radius, my_radius) # Dataframe to plot the ellipse

names(ellDF) <- c("Real", "Imaginary") # rename the columns


# plot the eigenvalues
p <- ggplot(eigDF, aes(x = Real, y = Imaginary))
p <- p +
  geom_point(shape = I(3)) +
  theme(legend.position = "none")

# now add the vertical and horizontal line
p <- p + geom_hline(aes(yintercept = 0))
p <- p + geom_vline(aes(xintercept = 0))

# finally, add the ellipse
p <- p + geom_polygon(data = ellDF, aes(x = Real, y = Imaginary, alpha = 1/20, fill = "red"))

# save the result figure as a file called Girko.pdf
pdf("../result/Girko.pdf")
p
graphics.off()


**********************************************************************

Testing Girko.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error or warning:
Installing package into ‘/usr/local/lib/R/site-library’
(as ‘lib’ is unspecified)
Warning in install.packages("ggplot2") :
  'lib = "/usr/local/lib/R/site-library"' is not writable
Error in install.packages("ggplot2") : unable to install packages
Execution halted

======================================================================
Inspecting script file GPDD_Data.R...

File contents are:

**********************************************************************
# using the maps package in R to do mapping 

# load the Global Population Dynamics Database(GPDD) which is available on TheMulQuaBio git repository
load("../data/GPDDFiltered.RData")

# load dependence packages
library(maps)
library(ggplot2)

# draw a world map
mp <- NULL
mapworld<-borders("world",colour = "gray50",fill="white")
mp <- ggplot() + mapworld + ylim(-60,90)

# create new values for latitude and longitude information of gpdd dataframe
long <- gpdd$long
lat <- gpdd$lat

# superimpose on the map all the locations from gpdd dataframe
mp2 <- mp + geom_point(data=gpdd, aes(x=long,y=lat, colour=common.name))

# draw the graphic without legend and store it in a pdf in result directory
pdf("../result/gpdd.pdf", 14, 7)
mp2 + theme(legend.position = "none")
graphics.off()

# expected bias based on the data represented:
# 1. species in America continent and European continent are different
# 2. species near the sea and inland are different
# 3. different species have their own distrubution pattern




**********************************************************************

Testing GPDD_Data.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Code ran without errors or warnings

Time consumed = 1.33758s

======================================================================
Inspecting script file basic_io.R...

File contents are:

**********************************************************************
# A simple script to illustrate R input-output.
# Run line by line and check inputs outputs to understand what is happening
MyData <- read.csv("../data/trees.csv", header = TRUE) # import with headers

write.csv(MyData, "../result/MyData.csv") #write it out as a new file

write.table(MyData[1,], file = "../result/MyData.csv",append=TRUE) # Append to it

write.csv(MyData, "../result/MyData.csv", row.names=TRUE) # write row names

write.table(MyData, "../result/MyData.csv", col.names=FALSE) # ignore column names

**********************************************************************

Testing basic_io.R...

Output (only first 500 characters): 


**********************************************************************

**********************************************************************

Encountered error or warning:
Warning message:
In write.table(MyData[1, ], file = "../result/MyData.csv", append = TRUE) :
  appending column names to file

======================================================================
Inspecting script file DataWrangTidy.R...

File contents are:

**********************************************************************
################################################################
################## Wrangling the Pound Hill Dataset ############
################################################################

# load the tidyverse package
require(tidyverse) 

############# Load the dataset ###############
# header = false because the raw data don't have real headers
MyData <- as.matrix(read.csv("../data/PoundHillData.csv",header = F)) 

# header = true because we do have metadata headers
MyMetaData <- read.csv("../data/PoundHillMetaData.csv",header = T, sep=";", stringsAsFactors = F)

############# Inspect the dataset ###############
head(MyData) # show top 5 rows
dim(MyData)
dplyr::glimpse(MyData)
utils::View(MyData) #you can also do this
utils::View(MyMetaData)


############# Transpose ###############
# To get those species into columns and treatments into rows 
MyData <- t(MyData) 
head(MyData)   # show top 5 rows
dim(MyData)

############# Replace species absences with zeros ###############
MyData[MyData == ""] = 0

############# Convert raw matrix to data frame ###############

TempData <- as.data.frame(MyData[-1,],stringsAsFactors = F) #stringsAsFactors = F is important!
colnames(TempData) <- MyData[1,] # assign column names from original data

############# Convert from wide to long format  ###############

?gather #check out the gather function

# use species as key and count as value, other 4 variables as other selected columns
MyWrangledData <- TempData %>% gather(key = "Species", value = "Count", -Cultivation, -Block, -Plot, -Quadrat)

# transform the new dataframe variables to specific class
MyWrangledData[, "Cultivation"] <- as.factor(MyWrangledData[, "Cultivation"])
MyWrangledData[, "Block"] <- as.factor(MyWrangledData[, "Block"])
MyWrangledData[, "Plot"] <- as.factor(MyWrangledData[, "Plot"])
MyWrangledData[, "Quadrat"] <- as.factor(MyWrangledData[, "Quadrat"])
MyWrangledData[, "Count"] <- as.integer(MyWrangledData[, "Count"])

dplyr::glimpse(MyWrangledData)
slice(MyWrangledData, 1:5) # show top 5 rows
dim(MyWrangledData)

############# Exploring the data (extend the script below)  ###############

**********************************************************************

Testing DataWrangTidy.R...

Output (only first 500 characters): 


**********************************************************************
     V1                     V2        V3        V4        V5        V6       
[1,] "Cultivation"          "october" "october" "october" "october" "october"
[2,] "Block"                "a"       "a"       "a"       "a"       "a"      
[3,] "Plot"                 "1"       "1"       "1"       "1"       "1"      
[4,] "Quadrat"              "Q1"      "Q2"      "Q3"      "Q4"      "Q5"     
[5,] "Achillea millefolium" "4"       "8"       "3"       "20"      "6"      
[6,] "Agrostis gigantea"    ""   
**********************************************************************

Encountered error or warning:
Loading required package: tidyverse
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──
✔ ggplot2 3.3.2     ✔ purrr   0.3.4
✔ tibble  3.0.3     ✔ dplyr   1.0.1
✔ tidyr   1.1.1     ✔ stringr 1.4.0
✔ readr   1.3.1     ✔ forcats 0.5.0
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()

======================================================================
======================================================================
Finished running scripts

Ran into 9 errors or warnings

Total time used: 19.54s 

======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 94.5

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!